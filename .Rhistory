output <- as.data.frame((rmseErrorsHyperparameters))
output
output
# Grid search
searchGridSubCol <- expand.grid(subsample = c(0.5, 1),
colsample_bytree = c(0.5, 0.8),
max_depth = c(3, 5),
min_child = seq(1),
eta = c(0.01,0.1),
gamma = c(0,0.5,1)
)
system.time(
rmseErrorsHyperparameters <- apply(searchGridSubCol, 1, function(parameterList){
#Extract Parameters to test
currentSubsampleRate <- parameterList[["subsample"]]
currentColsampleRate <- parameterList[["colsample_bytree"]]
currentDepth <- parameterList[["max_depth"]]
currentEta <- parameterList[["eta"]]
currentMinChild <- parameterList[["min_child"]]
currentGamma <- parameterList[["gamma"]]
xgboostModelCV <- xgb.cv(data =  dtrain, nrounds = 200, nfold = 3, showsd = TRUE,
metrics = "auc", verbose = TRUE, "eval_metric" = "auc", "gamma" = currentGamma,
"objective" = "reg:logistic", "max.depth" = currentDepth, "eta" = currentEta,
"subsample" = currentSubsampleRate, "colsample_bytree" = currentColsampleRate
, print_every_n = 5, "min_child_weight" = currentMinChild, booster = "gbtree",
early_stopping_rounds = 10)
xvalidationScores <- as.data.frame(xgboostModelCV$evaluation_log)
rmse <- tail(xvalidationScores$test_rmse_mean, 1)
trmse <- tail(xvalidationScores$train_rmse_mean,1)
output <- return(c(rmse, trmse, currentSubsampleRate, currentColsampleRate, currentDepth, currentEta, currentMinChild))
}))
output <- as.data.frame((rmseErrorsHyperparameters))
head(output)
varnames <- c("train-auc", "test-auc", "SubSampRate", "ColSampRate", "Depth", "eta", "currentMinChild")
names(output) <- varnames
head(output)
head(xvalidationScores)
system.time(
rmseErrorsHyperparameters <- apply(searchGridSubCol, 1, function(parameterList){
#Extract Parameters to test
currentSubsampleRate <- parameterList[["subsample"]]
currentColsampleRate <- parameterList[["colsample_bytree"]]
currentDepth <- parameterList[["max_depth"]]
currentEta <- parameterList[["eta"]]
currentMinChild <- parameterList[["min_child"]]
currentGamma <- parameterList[["gamma"]]
xgboostModelCV <- xgb.cv(data =  dtrain, nrounds = 200, nfold = 3, showsd = TRUE,
metrics = "auc", verbose = TRUE, "eval_metric" = "auc", "gamma" = currentGamma,
"objective" = "reg:logistic", "max.depth" = currentDepth, "eta" = currentEta,
"subsample" = currentSubsampleRate, "colsample_bytree" = currentColsampleRate
, print_every_n = 5, "min_child_weight" = currentMinChild, booster = "gbtree",
early_stopping_rounds = 10)
xvalidationScores <- as.data.frame(xgboostModelCV$evaluation_log)
rmse <- tail(xvalidationScores$test_rmse_mean, 1)
trmse <- tail(xvalidationScores$train_rmse_mean,1)
output <- return(c(rmse, trmse, currentSubsampleRate, currentColsampleRate, currentDepth, currentEta, currentMinChild))
return(xvalidationScores)
}))
head(xvalidationScores)
View(output)
?searchGridSubCol
??searchGridSubCol
searchGridSubCol <- expand.grid(subsample = c(0.5, 1),
colsample_bytree = c(0.5, 0.8),
max_depth = c(3, 5),
min_child = seq(1),
eta = c(0.01,0.1),
gamma = c(0.5,1)
)
system.time(
aucErrorsHyperparameters <- apply(searchGridSubCol, 1, function(parameterList){
#Extract Parameters to test
currentSubsampleRate <- parameterList[["subsample"]]
currentColsampleRate <- parameterList[["colsample_bytree"]]
currentDepth <- parameterList[["max_depth"]]
currentEta <- parameterList[["eta"]]
currentMinChild <- parameterList[["min_child"]]
currentGamma <- parameterList[["gamma"]]
xgboostModelCV <- xgb.cv(data =  dtrain, nrounds = 200, nfold = 3, showsd = TRUE,
metrics = "auc", verbose = TRUE, "eval_metric" = "auc", "gamma" = currentGamma,
"objective" = "reg:logistic", "max.depth" = currentDepth, "eta" = currentEta,
"subsample" = currentSubsampleRate, "colsample_bytree" = currentColsampleRate
, print_every_n = 5, "min_child_weight" = currentMinChild, booster = "gbtree",
early_stopping_rounds = 10)
xvalidationScores <- as.data.frame(xgboostModelCV$evaluation_log)
aucErrorsHyperparameters <- tail(xvalidationScores$test_auc_mean, 1)
tauc <- tail(xvalidationScores$train_auc_mean,1)
output <- return(c(auc, tauc, currentSubsampleRate, currentColsampleRate, currentDepth, currentEta, currentMinChild))
}))
output <- as.data.frame((rmseErrorsHyperparameters))
head(output)
varnames <- c("train-auc", "test-auc", "SubSampRate", "ColSampRate", "Depth", "eta", "currentMinChild")
names(output) <- varnames
head(output)
searchGridSubCol <- expand.grid(subsample = c(0.5, 1),
colsample_bytree = c(0.5, 0.8),
max_depth = c(3, 5),
min_child = seq(1),
eta = c(0.01,0.1),
gamma = c(0.5,1)
)
system.time(
aucErrorsHyperparameters <- apply(searchGridSubCol, 1, function(parameterList){
#Extract Parameters to test
currentSubsampleRate <- parameterList[["subsample"]]
currentColsampleRate <- parameterList[["colsample_bytree"]]
currentDepth <- parameterList[["max_depth"]]
currentEta <- parameterList[["eta"]]
currentMinChild <- parameterList[["min_child"]]
currentGamma <- parameterList[["gamma"]]
xgboostModelCV <- xgb.cv(data =  dtrain, nrounds = 200, nfold = 3, showsd = TRUE,
metrics = "auc", verbose = TRUE, "eval_metric" = "auc", "gamma" = currentGamma,
"objective" = "reg:logistic", "max.depth" = currentDepth, "eta" = currentEta,
"subsample" = currentSubsampleRate, "colsample_bytree" = currentColsampleRate
, print_every_n = 5, "min_child_weight" = currentMinChild, booster = "gbtree",
early_stopping_rounds = 10)
xvalidationScores <- as.data.frame(xgboostModelCV$evaluation_log)
auc <- tail(xvalidationScores$test_auc_mean, 1)
tauc <- tail(xvalidationScores$train_auc_mean,1)
output <- return(c(auc, tauc, currentSubsampleRate, currentColsampleRate, currentDepth, currentEta, currentMinChild))
return(xvalidationScores)
}))
output <- as.data.frame((rmseErrorsHyperparameters))
head(output)
varnames <- c("train-auc", "test-auc", "SubSampRate", "ColSampRate", "Depth", "eta", "currentMinChild")
names(output) <- varnames
head(output)
output
xgboostModelCV$evaluation_log
print(test$ID_CPTE)
searchGridSubCol <- expand.grid(subsample = c(0.5, 1),
colsample_bytree = c(0.5, 0.8),
max_depth = c(4, 6),
min_child = seq(1),
eta = c(0.01,0.1),
gamma = c(0.5,1)
)
cv_function <- function(parameterList){
#Extract Parameters to test
currentSubsampleRate <- parameterList[["subsample"]]
currentColsampleRate <- parameterList[["colsample_bytree"]]
currentDepth <- parameterList[["max_depth"]]
currentEta <- parameterList[["eta"]]
currentMinChild <- parameterList[["min_child"]]
currentGamma <- parameterList[["gamma"]]
xgboostModelCV <- xgb.cv(data =  dtrain, nrounds = 200, nfold = 3, showsd = TRUE,
metrics = "auc", verbose = TRUE, "eval_metric" = "auc", "gamma" = currentGamma,
"objective" = "reg:logistic", "max.depth" = currentDepth, "eta" = currentEta,
"subsample" = currentSubsampleRate, "colsample_bytree" = currentColsampleRate
, print_every_n = 5, "min_child_weight" = currentMinChild, booster = "gbtree",
early_stopping_rounds = 10)
print(xgboostModelCV$evaluation_log)
xvalidationScores <- as.data.frame(xgboostModelCV$evaluation_log)
auc <- tail(xvalidationScores$test_auc_mean, 1)
tauc <- tail(xvalidationScores$train_auc_mean,1)
output <- return(c(auc, tauc, currentSubsampleRate, currentColsampleRate, currentDepth, currentEta, currentMinChild))
return(xvalidationScores)
}
system.time(
aucErrorsHyperparameters <- apply(searchGridSubCol, 1, cv_function)
)
searchGridSubCol <- expand.grid(subsample = c(0.5, 1),
colsample_bytree = c(0.5, 0.8),
max_depth = c(4, 6),
min_child = seq(1),
eta = c(0.01,0.1),
gamma = c(0.5,1)
)
cv_function <- function(parameterList){
#Extract Parameters to test
currentSubsampleRate <- parameterList[["subsample"]]
currentColsampleRate <- parameterList[["colsample_bytree"]]
currentDepth <- parameterList[["max_depth"]]
currentEta <- parameterList[["eta"]]
currentMinChild <- parameterList[["min_child"]]
currentGamma <- parameterList[["gamma"]]
xgboostModelCV <- xgb.cv(data =  dtrain, nrounds = 200, nfold = 3, showsd = TRUE,
metrics = "auc", verbose = TRUE, "eval_metric" = "auc", "gamma" = currentGamma,
"objective" = "binary:logistic", "max.depth" = currentDepth, "eta" = currentEta,
"subsample" = currentSubsampleRate, "colsample_bytree" = currentColsampleRate
, print_every_n = 5, "min_child_weight" = currentMinChild, booster = "gbtree",
early_stopping_rounds = 10)
#print(xgboostModelCV$evaluation_log)
xvalidationScores <- as.data.frame(xgboostModelCV$evaluation_log)
auc <- tail(xvalidationScores$train_auc_mean, 1)
tauc <- tail(xvalidationScores$test_auc_mean,1)
output <- return(c(auc, tauc, currentSubsampleRate, currentColsampleRate, currentDepth, currentEta, currentMinChild, currentGamma))
return(xvalidationScores)
}
system.time(
aucErrorsHyperparameters <- apply(searchGridSubCol, 1, cv_function)
)
output <- as.data.frame((aucErrorsHyperparameters))
head(output)
varnames <- c("train-auc", "test-auc", "SubSampRate", "ColSampRate", "Depth", "eta", "currentMinChild", "Gamma")
names(output) <- varnames
head(output)
output
output
paste(getwd(), "xgb_gridsearch.csv")
write.csv(paste0(getwd(), "/xgb_gridsearch.csv"))
searchGridSubCol <- expand.grid(subsample = c(0.8, 1),
colsample_bytree = c(0.8),
max_depth = c(3, 5),
min_child = seq(1),
eta = c(0.01,0.1),
gamma = c(0.5,1)
)
cv_function <- function(parameterList){
#Extract Parameters to test
currentSubsampleRate <- parameterList[["subsample"]]
currentColsampleRate <- parameterList[["colsample_bytree"]]
currentDepth <- parameterList[["max_depth"]]
currentEta <- parameterList[["eta"]]
currentMinChild <- parameterList[["min_child"]]
currentGamma <- parameterList[["gamma"]]
xgboostModelCV <- xgb.cv(data =  dtrain, nrounds = 200, nfold = 10, showsd = TRUE,
metrics = "auc", verbose = TRUE, "eval_metric" = "auc", "gamma" = currentGamma,
"objective" = "binary:logistic", "max.depth" = currentDepth, "eta" = currentEta,
"subsample" = currentSubsampleRate, "colsample_bytree" = currentColsampleRate
, print_every_n = 5, "min_child_weight" = currentMinChild, booster = "gbtree",
early_stopping_rounds = 10)
#print(xgboostModelCV$evaluation_log)
xvalidationScores <- as.data.frame(xgboostModelCV$evaluation_log)
auc <- tail(xvalidationScores$train_auc_mean, 1)
tauc <- tail(xvalidationScores$test_auc_mean,1)
output <- return(c(auc, tauc, currentSubsampleRate, currentColsampleRate, currentDepth, currentEta, currentMinChild, currentGamma))
return(xvalidationScores)
}
system.time(
aucErrorsHyperparameters <- apply(searchGridSubCol, 1, cv_function)
)
output <- as.data.frame((aucErrorsHyperparameters))
head(output)
varnames <- c("train-auc", "test-auc", "SubSampRate", "ColSampRate", "Depth", "eta", "currentMinChild", "Gamma")
names(output) <- varnames
output
write.csv(paste0(getwd(), "/xgb_gridsearch.csv"))
write.csv(output,paste0(getwd(), "/xgb_gridsearch.csv"))
## Grid search
searchGridSubCol <- expand.grid(subsample = c(0.8, 1),
colsample_bytree = c(0.8),
max_depth = c(3, 5),
min_child = seq(1),
eta = c(0.01,0.1),
gamma = c(0.5,1)
)
cv_function <- function(parameterList){
#Extract Parameters to test
currentSubsampleRate <- parameterList[["subsample"]]
currentColsampleRate <- parameterList[["colsample_bytree"]]
currentDepth <- parameterList[["max_depth"]]
currentEta <- parameterList[["eta"]]
currentMinChild <- parameterList[["min_child"]]
currentGamma <- parameterList[["gamma"]]
xgboostModelCV <- xgb.cv(data =  dtrain, nrounds = 300, nfold = 10, showsd = TRUE,
metrics = "auc", verbose = TRUE, "eval_metric" = "auc", "gamma" = currentGamma,
"objective" = "binary:logistic", "max.depth" = currentDepth, "eta" = currentEta,
"subsample" = currentSubsampleRate, "colsample_bytree" = currentColsampleRate
, print_every_n = 5, "min_child_weight" = currentMinChild, booster = "gbtree",
early_stopping_rounds = 10)
#print(xgboostModelCV$evaluation_log)
xvalidationScores <- as.data.frame(xgboostModelCV$evaluation_log)
auc <- tail(xvalidationScores$train_auc_mean, 1)
tauc <- tail(xvalidationScores$test_auc_mean,1)
output <- return(c(auc, tauc, currentSubsampleRate, currentColsampleRate, currentDepth, currentEta, currentMinChild, currentGamma))
return(xvalidationScores)
}
system.time(
aucErrorsHyperparameters <- apply(searchGridSubCol, 1, cv_function)
)
output <- as.data.frame((aucErrorsHyperparameters))
head(output)
write.csv(output,paste0(getwd(), "/xgb_gridsearch.csv"))
searchGridSubCol <- expand.grid(subsample = 0.8,
colsample_bytree = c(0.8),
max_depth = 3,
min_child = C(1,20,50),
eta = 0.1,
gamma = 1
)
cv_function <- function(parameterList){
#Extract Parameters to test
currentSubsampleRate <- parameterList[["subsample"]]
currentColsampleRate <- parameterList[["colsample_bytree"]]
currentDepth <- parameterList[["max_depth"]]
currentEta <- parameterList[["eta"]]
currentMinChild <- parameterList[["min_child"]]
currentGamma <- parameterList[["gamma"]]
xgboostModelCV <- xgb.cv(data =  dtrain, nrounds = 300, nfold = 10, showsd = TRUE,
metrics = "auc", verbose = TRUE, "eval_metric" = "auc", "gamma" = currentGamma,
"objective" = "binary:logistic", "max.depth" = currentDepth, "eta" = currentEta,
"subsample" = currentSubsampleRate, "colsample_bytree" = currentColsampleRate
, print_every_n = 5, "min_child_weight" = currentMinChild, booster = "gbtree",
early_stopping_rounds = 10)
#print(xgboostModelCV$evaluation_log)
xvalidationScores <- as.data.frame(xgboostModelCV$evaluation_log)
auc <- tail(xvalidationScores$train_auc_mean, 1)
tauc <- tail(xvalidationScores$test_auc_mean,1)
output <- return(c(auc, tauc, currentSubsampleRate, currentColsampleRate, currentDepth, currentEta, currentMinChild, currentGamma))
return(xvalidationScores)
}
system.time(
aucErrorsHyperparameters <- apply(searchGridSubCol, 1, cv_function)
)
output <- as.data.frame((aucErrorsHyperparameters))
output
## Keeping the model under control
params <- list(booster = "gbtree", objective = "binary:logistic", eta = 0.1, gamma = 1,
max_depth = 3, min_child_weight = 20, subsample = 0.8, colsample_bytree = 0.8)
# xgbcv <- xgb.cv(params = params, data = dtrain, nrounds = 300, nfold = 10, showsd = T, stratified = T,
#                 print_every_n = 5, early_stopping_rounds = 10)
## Model with optimal parameters
xgb1 <- xgb.train(params = params
,data = dtrain
,nrounds = 300
,watchlist = list(val=dtest,train=dtrain)
,print_every_n = 10
,early_stopping_round = 10
,maximize = F
,eval_metric = "auc"
)
xgbpred <- predict(xgb1,dtest)
# xgbpred <- ifelse(xgbpred > 0.5,1,0)
# confusionMatrix(xgbpred, test_label)
## Calculate ROC
roc.curve(model_test$Default,xgbpred)
## Keeping the model under control
params <- list(booster = "gbtree", objective = "binary:logistic", eta = 0.1, gamma = 1,
max_depth = 3, min_child_weight = 20, subsample = 0.8, colsample_bytree = 0.8)
# xgbcv <- xgb.cv(params = params, data = dtrain, nrounds = 300, nfold = 10, showsd = T, stratified = T,
#                 print_every_n = 5, early_stopping_rounds = 10)
## Model with optimal parameters
xgb1 <- xgb.train(params = params
,data = dtrain
,nrounds = 300
,watchlist = list(val=dtest,train=dtrain)
,print_every_n = 2
,early_stopping_round = 20
#,maximize = F
,eval_metric = "auc"
)
xgbpred <- predict(xgb1,dtest)
# xgbpred <- ifelse(xgbpred > 0.5,1,0)
# confusionMatrix(xgbpred, test_label)
## Calculate ROC
roc.curve(model_test$Default,xgbpred)
he model under control
params <- list(booster = "gbtree", objective = "binary:logistic", eta = 0.1, gamma = 1,
max_depth = 3, min_child_weight = 1, subsample = 0.8, colsample_bytree = 0.8)
# xgbcv <- xgb.cv(params = params, data = dtrain, nrounds = 300, nfold = 10, showsd = T, stratified = T,
#                 print_every_n = 5, early_stopping_rounds = 10)
## Model with optimal parameters
xgb1 <- xgb.train(params = params
,data = dtrain
,nrounds = 300
,watchlist = list(val=dtest,train=dtrain)
,print_every_n = 2
,early_stopping_round = 20
#,maximize = F
,eval_metric = "auc"
)
xgbpred <- predict(xgb1,dtest)
# xgbpred <- ifelse(xgbpred > 0.5,1,0)
# confusionMatrix(xgbpred, test_label)
## Calculate ROC
roc.curve(model_test$Default,xgbpred)
xgb1 <- xgb.train(params = params
,data = dtrain
,nrounds = 100
,watchlist = list(val=dtest,train=dtrain)
,print_every_n = 2
,early_stopping_round = 10
#,maximize = F
,eval_metric = "auc"
)
xgbpred <- predict(xgb1,dtest)
# xgbpred <- ifelse(xgbpred > 0.5,1,0)
# confusionMatrix(xgbpred, test_label)
## Calculate ROC
roc.curve(model_test$Default,xgbpred)
xgb1 <- xgb.train(params = params
,data = dtrain
,nrounds = 200
,watchlist = list(val=dtest,train=dtrain)
,print_every_n = 2
,early_stopping_round = 5
#,maximize = F
,eval_metric = "auc"
)
xgbpred <- predict(xgb1,dtest)
# xgbpred <- ifelse(xgbpred > 0.5,1,0)
# confusionMatrix(xgbpred, test_label)
## Calculate ROC
roc.curve(model_test$Default,xgbpred)
## Keeping the model under control
params <- list(booster = "gbtree", objective = "binary:logistic", eta = 0.1, gamma = 5,
max_depth = 3, min_child_weight = 5, subsample = 0.8, colsample_bytree = 0.8)
# xgbcv <- xgb.cv(params = params, data = dtrain, nrounds = 300, nfold = 10, showsd = T, stratified = T,
#                 print_every_n = 5, early_stopping_rounds = 10)
## Model with optimal parameters
xgb1 <- xgb.train(params = params
,data = dtrain
,nrounds = 200
,watchlist = list(val=dtest,train=dtrain)
,print_every_n = 2
,early_stopping_round = 5
#,maximize = F
,eval_metric = "auc"
)
xgbpred <- predict(xgb1,dtest)
# xgbpred <- ifelse(xgbpred > 0.5,1,0)
# confusionMatrix(xgbpred, test_label)
## Calculate ROC
roc.curve(model_test$Default,xgbpred)
## Keeping the model under control
params <- list(booster = "gbtree", objective = "binary:logistic", eta = 0.1, gamma = 5,
max_depth = 3, min_child_weight = 1, subsample = 0.8, colsample_bytree = 0.8)
# xgbcv <- xgb.cv(params = params, data = dtrain, nrounds = 300, nfold = 10, showsd = T, stratified = T,
#                 print_every_n = 5, early_stopping_rounds = 10)
## Model with optimal parameters
xgb1 <- xgb.train(params = params
,data = dtrain
,nrounds = 200
,watchlist = list(val=dtest,train=dtrain)
,print_every_n = 2
,early_stopping_round = 5
#,maximize = F
,eval_metric = "auc"
)
xgbpred <- predict(xgb1,dtest)
# xgbpred <- ifelse(xgbpred > 0.5,1,0)
# confusionMatrix(xgbpred, test_label)
## Calculate ROC
roc.curve(model_test$Default,xgbpred)
## Keeping the model under control
params <- list(booster = "gbtree", objective = "binary:logistic", eta = 0.1, gamma = 5,
max_depth = 5, min_child_weight = 1, subsample = 0.8, colsample_bytree = 0.8)
# xgbcv <- xgb.cv(params = params, data = dtrain, nrounds = 300, nfold = 10, showsd = T, stratified = T,
#                 print_every_n = 5, early_stopping_rounds = 10)
## Model with optimal parameters
xgb1 <- xgb.train(params = params
,data = dtrain
,nrounds = 200
,watchlist = list(val=dtest,train=dtrain)
,print_every_n = 2
,early_stopping_round = 5
#,maximize = F
,eval_metric = "auc"
)
xgbpred <- predict(xgb1,dtest)
# xgbpred <- ifelse(xgbpred > 0.5,1,0)
# confusionMatrix(xgbpred, test_label)
## Calculate ROC
roc.curve(model_test$Default,xgbpred)
## Keeping the model under control
params <- list(booster = "gbtree", objective = "binary:logistic", eta = 0.15, gamma = 5,
max_depth = 3, min_child_weight = 1, subsample = 0.8, colsample_bytree = 0.8)
# xgbcv <- xgb.cv(params = params, data = dtrain, nrounds = 300, nfold = 10, showsd = T, stratified = T,
#                 print_every_n = 5, early_stopping_rounds = 10)
## Model with optimal parameters
xgb1 <- xgb.train(params = params
,data = dtrain
,nrounds = 200
,watchlist = list(val=dtest,train=dtrain)
,print_every_n = 2
,early_stopping_round = 5
#,maximize = F
,eval_metric = "auc"
)
xgbpred <- predict(xgb1,dtest)
# xgbpred <- ifelse(xgbpred > 0.5,1,0)
# confusionMatrix(xgbpred, test_label)
## Calculate ROC
roc.curve(model_test$Default,xgbpred)
## Keeping the model under control
params <- list(booster = "gbtree", objective = "binary:logistic", eta = 0.1, gamma = 5,
max_depth = 3, min_child_weight = 1, subsample = 0.8, colsample_bytree = 0.8)
# xgbcv <- xgb.cv(params = params, data = dtrain, nrounds = 300, nfold = 10, showsd = T, stratified = T,
#                 print_every_n = 5, early_stopping_rounds = 10)
## Model with optimal parameters
xgb1 <- xgb.train(params = params
,data = dtrain
,nrounds = 200
,watchlist = list(val=dtest,train=dtrain)
,print_every_n = 2
,early_stopping_round = 5
#,maximize = F
,eval_metric = "auc"
)
xgbpred <- predict(xgb1,dtest)
# xgbpred <- ifelse(xgbpred > 0.5,1,0)
# confusionMatrix(xgbpred, test_label)
## Calculate ROC
roc.curve(model_test$Default,xgbpred)
## Final prediction for submission
test_final_label <- as.numeric(as.factor(test$Default))-1
test_final_xgb <- as.matrix(copy(test[,colnames(test) %in% c(revised_vars,"Default")]))
dtest_final <- xgb.DMatrix(data = test_final_xgb,
label = test_final_label)
xgb_submission <- predict(xgb1,dtest_final)
#--------------------------------------------------------#
# 3. Submission
# ______________________________________________________
#
#   - Create submission .csv
#--------------------------------------------------------#
test$final_pred <- xgb_submission
submission <- data.frame(test$ID_CPTE, test$final_pred)
colnames(submission) = c("ID_CPTE", "Default")
#submission_final = merge(submission,performance_test, by = "ID_CPTE")
write.csv(submission,paste0(getwd(),"/Submissions/submission_2_JUL11_probs.csv"))
